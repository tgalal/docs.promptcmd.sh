import{_ as i,c as a,o as t,ah as e}from"./chunks/framework.BJEpWshW.js";const c=JSON.parse('{"title":"Monitoring Usage","description":"","frontmatter":{},"headers":[],"relativePath":"concepts/monitoring_usage.md","filePath":"concepts/monitoring_usage.md"}'),n={name:"concepts/monitoring_usage.md"};function l(h,s,p,r,o,k){return t(),a("div",null,[...s[0]||(s[0]=[e(`<h1 id="monitoring-usage" tabindex="-1">Monitoring Usage <a class="header-anchor" href="#monitoring-usage" aria-label="Permalink to “Monitoring Usage”">​</a></h1><p>Track API usage, token consumption, and performance metrics across all your prompts and providers using <code>promptctl stats</code>.</p><h2 id="view-all-statistics" tabindex="-1">View All Statistics <a class="header-anchor" href="#view-all-statistics" aria-label="Permalink to “View All Statistics”">​</a></h2><p>Track usage across all providers and models:</p><div class="language-bash"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;user-select:none;-webkit-user-select:none;">$ </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">promptctl</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> stats</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">provider</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">      model</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">                     runs</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">     prompt</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> tokens</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">     completion</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> tokens</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">     avg</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> tps</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">anthropic</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">     claude-opus-4-5</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">           15</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">       1988</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">              1562</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">                  31</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">openai</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">        gpt-5-mini-2025-08-07</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">     2</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        88</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">                380</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">                   42</span></span></code></pre></div><p>This shows:</p><ul><li><strong>provider</strong>: The LLM provider used</li><li><strong>model</strong>: The specific model invoked</li><li><strong>runs</strong>: Number of times the prompt was executed</li><li><strong>prompt tokens</strong>: Total input tokens consumed</li><li><strong>completion tokens</strong>: Total output tokens generated</li><li><strong>avg tps</strong>: Average tokens per second (throughput, indicating generation speed)</li></ul><div class="info custom-block"><p class="custom-block-title custom-block-title-default">INFO</p><p>Statistics are stored in <code>~/.promptcmd/stats.db</code>. See <a href="/intro/lookup-paths">Lookup Paths</a> for more details on file locations.</p></div><h2 id="view-last-execution" tabindex="-1">View Last Execution <a class="header-anchor" href="#view-last-execution" aria-label="Permalink to “View Last Execution”">​</a></h2><p>View statistics for the most recent prompt execution:</p><div class="language-bash"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;user-select:none;-webkit-user-select:none;">$ </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">promptctl</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> stats</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> --last</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">provider</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">      model</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">               prompt</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> tokens</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">     completion</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> tokens</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">     time</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">anthropic</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">     claude-opus-4-5</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">     206</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">               168</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">                   5</span></span></code></pre></div><p>The <strong>time</strong> column shows the execution duration in seconds. This is useful for debugging or understanding the token usage and performance of a specific prompt run.</p><h2 id="dry-run-testing" tabindex="-1">Dry Run Testing <a class="header-anchor" href="#dry-run-testing" aria-label="Permalink to “Dry Run Testing”">​</a></h2><p>You can test prompts using <code>promptctl run --dry</code> to preview what will be sent without calling the API:</p><div class="language-bash"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;user-select:none;-webkit-user-select:none;">$ </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">promptctl</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> run</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> --dry</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> PROMPTNAME</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> --</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [PROMPT </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">ARGS]</span></span></code></pre></div><p>This lets you validate your prompt template and arguments without consuming tokens or incurring API costs. See <a href="/concepts/exec#dry-run-mode">Executing Prompts</a> for more details on dry run mode with other execution methods.</p><h2 id="caching" tabindex="-1">Caching <a class="header-anchor" href="#caching" aria-label="Permalink to “Caching”">​</a></h2><p>See <a href="/configuration/caching">Caching</a></p>`,18)])])}const g=i(n,[["render",l]]);export{c as __pageData,g as default};
